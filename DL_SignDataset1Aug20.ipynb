{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PTwAwoLJwJ94tZHYhmGMNfvJqOSc5-Y0",
      "authorship_tag": "ABX9TyP8L/b2odLQFqc6mOqumq6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahmanziaur/GradThesisICT18-Colab/blob/main/DL_SignDataset1Aug20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arda Mavi\n",
        "import os\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import imageio.v2 as imageio\n",
        "#from scipy.misc import imresize\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Settings:\n",
        "img_size = 64\n",
        "grayscale_images = True\n",
        "num_class = 10\n",
        "test_size = 0.2\n",
        "\n",
        "\n",
        "def get_img(data_path):\n",
        "    # Getting image array from path:\n",
        "    img = imageio.imread(data_path, flatten=grayscale_images)\n",
        "    img = imageio.imresize(img, (img_size, img_size, 1 if grayscale_images else 3))\n",
        "    return img\n",
        "\n",
        "#dataset https://github.com/rahmanziaur/GradThesisICT18-Colab/tree/main/Datasets\n",
        "\n",
        "def get_dataset(dataset_path='Dataset'):\n",
        "    # Getting all data from data path:\n",
        "    try:\n",
        "        X = np.load('/content/X.npy')\n",
        "        Y = np.load('/content/Y.npy')\n",
        "    except:\n",
        "        labels = listdir(dataset_path) # Geting labels\n",
        "        X = []\n",
        "        Y = []\n",
        "        for i, label in enumerate(labels):\n",
        "            datas_path = dataset_path+'/'+label\n",
        "            for data in listdir(datas_path):\n",
        "                img = get_img(datas_path+'/'+data)\n",
        "                X.append(img)\n",
        "                Y.append(i)\n",
        "        # Create dateset:\n",
        "        X = 1-np.array(X).astype('float32')/255.\n",
        "        Y = np.array(Y).astype('float32')\n",
        "        Y = to_categorical(Y, num_class)\n",
        "        if not os.path.exists('npy_dataset/'):\n",
        "            os.makedirs('npy_dataset/')\n",
        "        np.save('npy_dataset/X.npy', X)\n",
        "        np.save('npy_dataset/Y.npy', Y)\n",
        "    X, X_test, Y, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
        "    return X, X_test, Y, Y_test\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    get_dataset()"
      ],
      "metadata": {
        "id": "HmYx16RuuJ0c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WlQ4dYtrwFLm"
      }
    }
  ]
}